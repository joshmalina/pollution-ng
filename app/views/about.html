<h1 class="page-header">Behind the numbers</h1>

<p class="lead">Understand the learning model used, motivation for the task, and what the data looks like</p>

<p>
Air pollution in China is a grave concern for the environmental and public health of the country. The air quality in the capital is on average <a href="http://www.who.int/mediacentre/factsheets/fs313/en/">twice</a> what is considered healthy by the World Health Organization. Prolonged exposure to air pollution at the level experienced in Beijing is associated with heart disease, lung cancer and stroke.
</p>

<p>This project forecasts 10 days of hourly particulate estimates in Beijing based on historical pollution and weather records. While it will not mitigate the problem of toxic air for the city's more than <a href="https://en.wikipedia.org/wiki/Beijing">20 million</a> residents, it may allow them to manage their exposure to very bad (or good) air a few days in advance. When I lived in Beijing, I used <a href="http://banshirne.com">a similar tool</a> to exercise outside without wearing a <a href="http://www.greenpeace.org/eastasia/news/blog/the-three-types-of-masks-that-protect-you-fro/blog/38232/">mask</a>.
<br>
<h2>The data</h2>

<p class="lead">There were roughly four kinds of data involved in this puzzle:</p>

<table class="table table-condensed table-bordered">
	<thead>
	<tr>
		<th>#</th>
		<th>Data</th>
		<th>Origin</th>
	</tr>
	<tr>
		<td>1</td><td>Historical Weather</td><td>Compiled hourly from the <a href="http://www.wunderground.com/weather/api/">Wunderground API</a></td>
	</tr>
	<tr>
		<td>2</td><td>Future Weather</td><td>Also available from Wunderground, as part of their 10-day forecast</td>
	</tr>
	<tr>
		<td>3</td><td>Historical Pollution</td><td>Collected and posted by the <a href="http://www.stateair.net/web/historical/1/1.html">US Embassy in Beijing</a></td>
	</tr>
	<tr>	
		<td>4</td><td>Future Pollution</td><td>Our task to come up with</td>
	</tr>	
	</thead>
</table>

<p>Each call to the Wunderground API exposed only 24 hours of weather data. With eight years of pollution data waiting to be matched, this <a href="https://github.com/joshmalina/pollution/blob/master/notebooks/Build_historical_weather_data.ipynb">required hundreds of calls to Wunderground, as well as a fair bit of cleaning, massaging and joining</a>.</p>

<p>Early exploration of the data set revealed that weather factors such as wind speed, humidity and air pressure were correlated with changes in particulate density, but were also correlated with each other. Seasonal trends in pollution values (from earlier research), and the fact that the data were part of a time series pointed toward a more flexible model. Early linear approximations performed poorly out of sample. Pollution values themselves were not normally distributed, and extreme points distributed widely outside a few standard deviations of the mean were not uncommon.</p>

<h2>How do machines learn?</h2>

<p>
The machine learning process is not so different from educating a child. It learns by exposure to diverse examples, by memorizing their characteristics, and generalizing its experience to novel observations. In a <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a> task such as ours, the machine is shown a bit of data and told, "This is some thing." It could be shown a cow feeding and told, "This is a cow". Then a different cow drinking water, nursing its young, or swatting flies from its buttocks -- and at each instance, again, "This is a cow". With enough observations and an actual pattern to be learned (this is necessary), the machine may correctly label new instances. Not unlike an anxious Pinocchio suddenly turned real, or a shimmering Ariel now walking amongst the ranks of the bipedal, the machine can meet a four legged beast with a swollen pink bladder and confidently declare, "This is a cow."</p>

<p>
Less figuratively, that final success is the output of an algorithmically tuned function of weights (one or more for each of the relevant predictors) that enables the machine to apply a label or number to a new input. The machine starts with a naive or randomly selected set of weights, which move in one direction or another depending on how the model is built. In this case, I've used an ensemble of bootstrapped decision trees whose features were also randomly selected, known as a <a href="https://en.wikipedia.org/wiki/Random_forest">random forest</a> to make predictions for the count (or density) of air pollution. It was a good fit for my problem because it was a flexible learning model that wasn't as resistant to high leverage points as a linear (or sort of linear) system. It also didn't require too much fine tuning. 

<img src="/images/tree_example.png" class="img-responsive"><label>A decision tree classifies vectors of features according to a series of conditions. Each input continues down the tree until arriving at a terminal node, where it waits for the rest of the data set to be processed. Upon completion, either a label or numeric value is assigned to all observations within and any new observations that happen down the same path.</label>

<p>
A decision tree is a learning model that sorts inputs into a set of terminal nodes (or leaves), where each observation is assigned to a predictive class or value. The tree sorts by "asking" the data a series of yes-no questions. From root to leaf: "Is humidity less than 43.5? If so, go left. Else, go right." Once all inputs are placed in a terminal node, a classification scheme or regression pattern will assign a value to that input and to all future inputs that arrive in the same node. </p>

<p>
A single tree alone is a poor model for generalization. It suffers from high variance -- small changes in inputs can lead to a very different approximation. This "instability" makes it unlikely to perform very well out of sample. Fortunately, if we grow many diverse trees and average their predictions we can lower our variance and thus our error without biasing the model too much. The sub-sampling is completed via the process <a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating">bagging.</a></p>

<p>
The random sampling of the predictors is the random forest part, in which each tree is grown with fewer than p predictors. For example, Tree 1 is grown on wind speed and humidity, whereas Tree 2 is grown using temperature and air pressure. By preserving some variety in our forest, our final product is even better suited to correctly classifying new observations. In the presence of a few highly predictive variables, this randomness preserves some diversity in tree construction.</p>

<p>
To get this random forest performing well, it is easy to set a large number of trees (500 or more) and allow it to build to any depth. However, since these results would need to be made available online (and there currently isn't a budget for a multi-node cluster of EC2 instances), it was important to minimize the size of the forest since it would be loaded into memory for the computations. Experimenting with different forest sizes showed that there was little decrease in error after about 100 trees.
</p>

<h2>A note on time series</h2> 

<p>
The data in this project exemplify a time series, wherein the pollution values are not independently selected from a population. Every value is highly correlated with those immediately following it and immediately preceding it, allowing us to use previous values as predictors as well, but also complicating our analysis since the observations are not independent. In probability, events A and B are independent if knowing that A occurs offers no insight into the likelihood of B occurring. That is, my wearing of pajamas and the queen eating a sandwich are independent since knowing one does not help in knowing the likelihood of the other.</p>

<p>
Since pollution values do not tend to completely refresh in the course of hour, the particulate count at 2 pm is likely still counting those that were around at 3 p.m. Our model is greatly improved by incorporating n - k previous prediction values, but it is important not to overweight its significance -- as the model forecasts further out in time, previous pollution values are merely educated guesses, and so we need to expect a larger degree of error as we get further out. </p>

<img src="/images/timeseries.png" class="img-responsive"><label>Pollution over the course of eight years in Beijing. The average is about 100, whereas 50 is the maximum that is considered healthy by the World Health Organization.</label>

<h2>Measuring success</h2>

<p>
So how did we do? Is the model any good, or just another <a href="http://www.catsthatlooklikehitler.com/">pointless website</a> taking up space on the internet? Our estimates on a test-set (a fraction of the data where the model was not trained) showed that our model explained nearly 78 percent of the variety in the target output (R-squared). This is a gauge of how our target (pollution) changes when the various weather predictions changed. If there is a strong correspondence, then we would see a higher R-squared. We also had an average error of around 32 (Root mean squared error), and we should expect this to be higher as we get further from the present.</p>

<h4>Sources of error and improvement</h4>

<p>
There are many reasons for why this model is not perfect. In machine learning applications, the error out of sample is a composition of error (which is itself a composition of bias and variance) in your model plus random noise, which is the sort of unexplained variation in a data set that is not captured causally. </p>

<p>
For data precision, it might have been a concern that the weather data and pollution data are not captured in exactly the same place in Beijing. Pollution data is reported from the US Embassy, whereas weather comes from a station at the Beijing Airport, which is about 12 miles away. Given the fluctuation in pollution readings across even short distances, this could be a concern for the integrity of the data set. A way to mitigate this effect would be to incorporate data from many pollution and weather sensors throughout the city and approximate an average for the city. </p>

<p>
Potentially even more important would be the inclusion of other variables, such as traffic patterns and variation in industrial output, which may be correlated with our target. If anyone reading this has access to that data, I would be very interested in incorporating it. </p>

<p>
Of course, we are also limited by the ability of meteorologists to make accurate forecasts, since our predictions are so heavily dependent on weather. This is not really an area where we can improve.</p>
<p>
Outside areas of error, our application could be improved in a couple important ways.</p>

<ol>
<li>
Per hour error could be calculate to show prediction error as a function of time</li>
<li>Visualizations could be improved</li>
</ol>

<h2>Sources</h2>
<p class="lead">The following authors and their books and course materials either directly inspired or helped me to understand or implement these learning methods</p>

<ol>
	<li>
Abu-Mostafa, Yaser. Learning from data. https://work.caltech.edu/telecourse.html -- An introductory machine learning course
	</li>
	<li>
Hastie, et al. An introduction to statistical learning. http://www-bcf.usc.edu/~gareth/ISL/ -- Great write up of all things machine learning, including construction of decision trees, random forests
	</li>
	<li>
	Hamner, Ben. http://blog.kaggle.com/2012/05/01/chucking-everything-into-a-random-forest-ben-hamner-on-winning-the-air-quality-prediction-hackathon/ -- Write up of method for winning air pollution hackathon </li>
	<li>
	US Dept of State Mission in China</li>
	<li>Wunderground API</li>
</ol>


<!-- 
improvements:

1. add some pairwise correlation images
2. show the importance table for features of the random forest
3. show a graph displaying error as a function of trees
-->

<!-- 
improvements to the model:
1. instead of using the n-5 value, train on the n-1 value, but give it less importance as n => 240
-->
